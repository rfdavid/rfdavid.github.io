---
---
References
==========

@InProceedings{you2020design,
  title     = {Design Space for Graph Neural Networks},
  author    = {You, Jiaxuan and Ying, Rex and Leskovec, Jure},
  booktitle = {NeurIPS},
  year      = {2020}
}

@book{abdi2007kendall,
  title     = {The kendall rank correlation coefficient},
  author    = {H. Abdi},
  year      = {2007},
  publisher = {Encyclopedia of Measurement and Statistics.}
}

@article{10.2307/2285666,
 ISSN      = {01621459},
 URL       = {http://www.jstor.org/stable/2285666},
 abstract  = {This paper treats essentially the first derivative of an estimator viewed as functional and the ways in which it can be used to study local robustness properties. A theory of robust estimation "near" strict parametric models is briefly sketched and applied to some classical situations. Relations between von Mises functionals, the jackknife and U-statistics are indicated. A number of classical and new estimators are discussed, including trimmed and Winsorized means, Huber-estimators, and more generally maximum likelihood and M-estimators. Finally, a table with some numerical robustness properties is given.},
 author    = {Frank R. Hampel},
 journal   = {Journal of the American Statistical Association},
 number    = {346},
 pages     = {383--393},
 publisher = {[American Statistical Association, Taylor & Francis, Ltd.]},
 title     = {The Influence Curve and Its Role in Robust Estimation},
 urldate   = {2022-07-27},
 volume    = {69},
 year      = {1974}
}

@InProceedings{pmlr-v70-koh17a,
  title     = {Understanding Black-box Predictions via Influence Functions},
  author    = {Pang Wei Koh and Percy Liang},
  booktitle = {Proceedings of the 34th International Conference on Machine Learning},
  pages     = {1885--1894},
  year      = {2017},
  editor    = {Precup, Doina and Teh, Yee Whye},
  volume    = {70},
  series    = {Proceedings of Machine Learning Research},
  month     = {06--11 Aug},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v70/koh17a/koh17a.pdf},
  url       = {https://proceedings.mlr.press/v70/koh17a.html},
  abstract  = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.}
}

@article{JMLR:v18:16-491,
  author  = {Naman Agarwal and Brian Bullins and Elad Hazan},
  title   = {Second-Order Stochastic Optimization for Machine Learning in Linear Time},
  journal = {Journal of Machine Learning Research},
  year    = {2017},
  volume  = {18},
  number  = {116},
  pages   = {1--40},
  url     = {http://jmlr.org/papers/v18/16-491.html}
}

@inproceedings{10.5555/3104322.3104416,
author    = {Martens, James},
title     = {Deep Learning via Hessian-Free Optimization},
year      = {2010},
isbn      = {9781605589077},
publisher = {Omnipress},
address   = {Madison, WI, USA},
abstract  = {We develop a 2nd-order optimization method based on the "Hessian-free" approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn't limited in applicability to auto-encoders, or any specific model class. We also discuss the issue of "pathological curvature" as a possible explanation for the difficulty of deep-learning and how 2nd-order optimization, and our method in particular, effectively deals with it.},
booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
pages     = {735–742},
numpages  = {8},
location  = {Haifa, Israel},
series    = {ICML'10}
}

@book{maronna2006robust,
  title     = {Robust Statistics: Theory and Methods},
  author    = {Maronna, R.A. and Martin, D.R. and Yohai, V.J.},
  isbn      = {9780470010921},
  series    = {Wiley Series in Probability and Statistics},
  url       = {https://books.google.ca/books?id=iFVjQgAACAAJ},
  year      = {2006},
  publisher = {Wiley}
}

@book{cook1982influence,
  title     = {Residuals and Influence in Regression },
  author    = {Cook, R. Dennis, and Sanford Weisberg},
  isbn      = {041224280X},
  series    = {Monographs on statistics and applied probability},
  url       = {https://franklin.library.upenn.edu/catalog/FRANKLIN_991342763503681},
  year      = {1982},
  publisher = {New York: Chapman and Hall}
}

@InProceedings{pmlr-v119-basu20b,
  title     = {On Second-Order Group Influence Functions for Black-Box Predictions},
  author    = {Basu, Samyadeep and You, Xuchen and Feizi, Soheil},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages     = {715--724},
  year      = {2020},
  editor    = {III, Hal Daumé and Singh, Aarti},
  volume    = {119},
  series    = {Proceedings of Machine Learning Research},
  month     = {13--18 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v119/basu20b/basu20b.pdf},
  url       = {https://proceedings.mlr.press/v119/basu20b.html},
  abstract  = {With the rapid adoption of machine learning systems in sensitive applications, there is an increasing need to make black-box models explainable. Often we want to identify an influential group of training samples in a particular test prediction for a given machine learning model. Existing influence functions tackle this problem by using first-order approximations of the effect of removing a sample from the training set on model parameters. To compute the influence of a group of training samples (rather than an individual point) in model predictions, the change in optimal model parameters after removing that group from the training set can be large. Thus, in such cases, the first-order approximation can be loose. In this paper, we address this issue and propose second-order influence functions for identifying influential groups in test-time predictions. For linear models, across different sizes and types of groups, we show that using the proposed second-order influence function improves the correlation between the computed influence values and the ground truth ones. We also show that second-order influence functions could be used with optimization techniques to improve the selection of the most influential group for a test-sample.} 
}

@inproceedings{NEURIPS2019_a78482ce,
  author    = {Koh, Pang Wei W and Ang, Kai-Siang and Teo, Hubert and Liang, Percy S},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {H. Wallach and H. Larochelle and A. Beygelzimer and F.  d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
  pages     = {},
  publisher = {Curran Associates, Inc.},
  title     = {On the Accuracy of Influence Functions for Measuring Group Effects},
  url       = {https://proceedings.neurips.cc/paper/2019/file/a78482ce76496fcf49085f2190e675b4-Paper.pdf},
  volume    = {32},
  year      = {2019}
}

@inproceedings{guo-etal-2021-fastif,
  title     = "{F}ast{IF}: Scalable Influence Functions for Efficient Model Interpretation and Debugging",
  author    = "Guo, Han  and Rajani, Nazneen  and Hase, Peter  and Bansal, Mohit  and Xiong, Caiming",
  booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
  month     = nov,
  year      = "2021",
  address   = "Online and Punta Cana, Dominican Republic",
  publisher = "Association for Computational Linguistics",
  url       = "https://aclanthology.org/2021.emnlp-main.808",
  doi       = "10.18653/v1/2021.emnlp-main.808",
  pages     = "10333--10350",
  abstract  = "Influence functions approximate the {``}influences{''} of training
  data-points for test predictions and have a wide variety of applications.
    Despite the popularity, their computational cost does not scale well
    with model and training data size. We present FastIF, a set of simple
    modifications to influence functions that significantly improves their
    run-time. We use k-Nearest Neighbors (kNN) to narrow the search space
    down to a subset of good candidate data points, identify the
    configurations that best balance the speed-quality trade-off in
    estimating the inverse Hessian-vector product, and introduce a fast
    parallel variant. Our proposed method achieves about 80X speedup while
    being highly correlated with the original influence values. With the
    availability of the fast influence functions, we demonstrate their
    usefulness in four applications. First, we examine whether influential
    data-points can {``}explain{''} test time behavior using the framework
    of simulatability. Second, we visualize the influence interactions
    between training and test data-points. Third, we show that we can
    correct model errors by additional fine-tuning on certain influential
    data-points, improving the accuracy of a trained MultiNLI model by
    2.5{\%} on the HANS dataset. Finally, we experiment with a similar
    setup but fine-tuning on datapoints not seen during training, improving
    the model accuracy by 2.8{\%} and 1.7{\%} on HANS and ANLI datasets
    respectively. Overall, our fast influence functions can be efficiently
    applied to large models and datasets, and our experiments demonstrate
    the potential of influence functions in model interpretation and
    correcting model errors.",
}

@inproceedings{
  basu2021influence,
    title     = {Influence Functions in Deep Learning Are Fragile},
    author    = {Samyadeep Basu and Phil Pope and Soheil Feizi},
    booktitle = {International Conference on Learning Representations},
    year      = {2021},
    url       = {https://openreview.net/forum?id=xHKVVHGDOEk}
}
